import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import silhouette_score, davies_bouldin_score
from sklearn.cluster import KMeans
from sklearn.decomposition import PCA
from typing import Dict, List, Tuple, Optional, Union
import warnings
warnings.filterwarnings('ignore')

# í•œê¸€ í°íŠ¸ ì„¤ì •
plt.rcParams['font.family'] = 'Malgun Gothic'
plt.rcParams['axes.unicode_minus'] = False


class UnsupervisedAnomalyEvaluator:
    """
    ë¹„ì§€ë„ ì´ìƒì¹˜ íƒì§€ ëª¨ë¸ì˜ ì„±ëŠ¥ì„ í‰ê°€í•˜ëŠ” í´ë˜ìŠ¤
    
    ë¼ë²¨ì´ ì—†ëŠ” ìƒí™©ì—ì„œ ë‹¤ì–‘í•œ ë°©ë²•ìœ¼ë¡œ ëª¨ë¸ì˜ ì„±ëŠ¥ì„ í‰ê°€í•©ë‹ˆë‹¤:
    1. Proxy-based í‰ê°€ (ì¬êµ¬ì„± ì˜¤ì°¨, êµ°ì§‘ ë¶„ë¦¬)
    2. í†µê³„ì  ë¶„ì„
    3. ì‹œê°ì  ë¶„ì„
    4. ë„ë©”ì¸ ê¸°ë°˜ í‰ê°€
    """
    
    def __init__(self):
        """í‰ê°€ê¸° ì´ˆê¸°í™”"""
        self.evaluation_results = {}
        
    def evaluate_reconstruction_error(self, 
                                   original_data: pd.DataFrame,
                                   reconstructed_data: pd.DataFrame,
                                   anomaly_scores: np.ndarray) -> Dict:
        """
        ì¬êµ¬ì„± ì˜¤ì°¨ ê¸°ë°˜ í‰ê°€ (ì¬êµ¬ì„± ê¸°ë°˜ ëª¨ë¸ìš©)
        
        Args:
            original_data: ì›ë³¸ ë°ì´í„°
            reconstructed_data: ì¬êµ¬ì„±ëœ ë°ì´í„°
            anomaly_scores: ì´ìƒ ì ìˆ˜
            
        Returns:
            Dict: ì¬êµ¬ì„± ì˜¤ì°¨ í‰ê°€ ê²°ê³¼
        """
        # MSE ê³„ì‚°
        mse = np.mean((original_data.values - reconstructed_data.values) ** 2, axis=1)
        
        # ì¬êµ¬ì„± ì˜¤ì°¨ì™€ ì´ìƒ ì ìˆ˜ì˜ ìƒê´€ê´€ê³„
        correlation = np.corrcoef(mse, anomaly_scores)[0, 1]
        
        # ì¬êµ¬ì„± ì˜¤ì°¨ í†µê³„
        mse_stats = {
            'mean': np.mean(mse),
            'std': np.std(mse),
            'min': np.min(mse),
            'max': np.max(mse),
            'q25': np.percentile(mse, 25),
            'q75': np.percentile(mse, 75),
            'iqr': np.percentile(mse, 75) - np.percentile(mse, 25)
        }
        
        # ì´ìƒ ì ìˆ˜ì™€ ì¬êµ¬ì„± ì˜¤ì°¨ì˜ ì¼ì¹˜ì„±
        # ë†’ì€ ì´ìƒ ì ìˆ˜ì™€ ë†’ì€ ì¬êµ¬ì„± ì˜¤ì°¨ê°€ ì¼ì¹˜í•˜ëŠ”ì§€ í™•ì¸
        high_anomaly = anomaly_scores > np.percentile(anomaly_scores, 90)
        high_reconstruction_error = mse > np.percentile(mse, 90)
        
        consistency = np.sum(high_anomaly & high_reconstruction_error) / np.sum(high_anomaly)
        
        results = {
            'mse_statistics': mse_stats,
            'correlation_with_anomaly_scores': correlation,
            'high_anomaly_consistency': consistency,
            'reconstruction_error': mse
        }
        
        return results
    
    def evaluate_cluster_separation(self, 
                                  data: pd.DataFrame,
                                  anomaly_scores: np.ndarray,
                                  n_clusters: int = 2) -> Dict:
        """
        êµ°ì§‘ ë¶„ë¦¬ ê¸°ë°˜ í‰ê°€
        
        Args:
            data: ì›ë³¸ ë°ì´í„°
            anomaly_scores: ì´ìƒ ì ìˆ˜
            n_clusters: êµ°ì§‘ ìˆ˜
            
        Returns:
            Dict: êµ°ì§‘ ë¶„ë¦¬ í‰ê°€ ê²°ê³¼
        """
        # PCAë¡œ ì°¨ì› ì¶•ì†Œ (ì‹œê°í™” ë° ê³„ì‚° íš¨ìœ¨ì„±)
        if data.shape[1] > 10:
            pca = PCA(n_components=10)
            data_reduced = pca.fit_transform(data)
        else:
            data_reduced = data.values
        
        # ì´ìƒ ì ìˆ˜ë¥¼ ê¸°ë°˜ìœ¼ë¡œ 2ê°œ êµ°ì§‘ìœ¼ë¡œ ë¶„í• 
        threshold = np.percentile(anomaly_scores, 90)  # ìƒìœ„ 10%ë¥¼ ì´ìƒì¹˜ë¡œ ê°„ì£¼
        cluster_labels = (anomaly_scores > threshold).astype(int)
        
        # Silhouette Score ê³„ì‚°
        try:
            silhouette = silhouette_score(data_reduced, cluster_labels)
        except:
            silhouette = 0.0
        
        # Davies-Bouldin Index ê³„ì‚°
        try:
            kmeans = KMeans(n_clusters=n_clusters, random_state=42, n_init=10)
            kmeans_labels = kmeans.fit_predict(data_reduced)
            davies_bouldin = davies_bouldin_score(data_reduced, kmeans_labels)
        except:
            davies_bouldin = float('inf')
        
        # êµ°ì§‘ ê°„ ê±°ë¦¬ì™€ êµ°ì§‘ ë‚´ ë¶„ì‚°
        cluster_0_indices = np.where(cluster_labels == 0)[0]
        cluster_1_indices = np.where(cluster_labels == 1)[0]
        
        if len(cluster_0_indices) > 0 and len(cluster_1_indices) > 0:
            # êµ°ì§‘ ë‚´ ë¶„ì‚°
            cluster_0_variance = np.var(data_reduced[cluster_0_indices], axis=0).mean()
            cluster_1_variance = np.var(data_reduced[cluster_1_indices], axis=0).mean()
            
            # êµ°ì§‘ ê°„ ê±°ë¦¬
            cluster_0_center = np.mean(data_reduced[cluster_0_indices], axis=0)
            cluster_1_center = np.mean(data_reduced[cluster_1_indices], axis=0)
            cluster_distance = np.linalg.norm(cluster_0_center - cluster_1_center)
            
            # ë¶„ë¦¬ ì§€ìˆ˜ (êµ°ì§‘ ê°„ ê±°ë¦¬ / (êµ°ì§‘ ë‚´ ë¶„ì‚°ì˜ í‰ê· ))
            separation_index = cluster_distance / ((cluster_0_variance + cluster_1_variance) / 2)
        else:
            cluster_0_variance = cluster_1_variance = cluster_distance = separation_index = 0.0
        
        results = {
            'silhouette_score': silhouette,
            'davies_bouldin_index': davies_bouldin,
            'cluster_0_variance': cluster_0_variance,
            'cluster_1_variance': cluster_1_variance,
            'cluster_distance': cluster_distance,
            'separation_index': separation_index,
            'cluster_labels': cluster_labels
        }
        
        return results
    
    def evaluate_statistical_properties(self, 
                                      anomaly_scores: np.ndarray,
                                      data: pd.DataFrame) -> Dict:
        """
        ì´ìƒ ì ìˆ˜ì˜ í†µê³„ì  íŠ¹ì„± í‰ê°€
        
        Args:
            anomaly_scores: ì´ìƒ ì ìˆ˜
            data: ì›ë³¸ ë°ì´í„°
            
        Returns:
            Dict: í†µê³„ì  íŠ¹ì„± í‰ê°€ ê²°ê³¼
        """
        # ì´ìƒ ì ìˆ˜ í†µê³„
        score_stats = {
            'mean': np.mean(anomaly_scores),
            'std': np.std(anomaly_scores),
            'min': np.min(anomaly_scores),
            'max': np.max(anomaly_scores),
            'q25': np.percentile(anomaly_scores, 25),
            'q75': np.percentile(anomaly_scores, 75),
            'iqr': np.percentile(anomaly_scores, 75) - np.percentile(anomaly_scores, 25),
            'skewness': self._calculate_skewness(anomaly_scores),
            'kurtosis': self._calculate_kurtosis(anomaly_scores)
        }
        
        # ì´ìƒ ì ìˆ˜ ë¶„í¬ì˜ ì •ê·œì„± ê²€ì • (Shapiro-Wilk)
        from scipy.stats import shapiro
        try:
            shapiro_stat, shapiro_p = shapiro(anomaly_scores)
            score_stats['shapiro_wilk_statistic'] = shapiro_stat
            score_stats['shapiro_wilk_pvalue'] = shapiro_p
            score_stats['is_normal_distribution'] = shapiro_p > 0.05
        except:
            score_stats['shapiro_wilk_statistic'] = None
            score_stats['shapiro_wilk_pvalue'] = None
            score_stats['is_normal_distribution'] = None
        
        # ì´ìƒ ì ìˆ˜ì™€ ì›ë³¸ ë°ì´í„°ì˜ ìƒê´€ê´€ê³„
        correlations = {}
        for col in data.columns:
            try:
                corr = np.corrcoef(anomaly_scores, data[col].values)[0, 1]
                correlations[f'correlation_with_{col}'] = corr
            except:
                correlations[f'correlation_with_{col}'] = 0.0
        
        # ì´ìƒ ì ìˆ˜ì˜ ë³€í™”ìœ¨
        score_changes = np.diff(anomaly_scores)
        change_stats = {
            'mean_change': np.mean(score_changes),
            'std_change': np.std(score_changes),
            'max_change': np.max(np.abs(score_changes)),
            'change_stability': 1.0 / (1.0 + np.std(score_changes))  # ë³€í™”ê°€ ì ì„ìˆ˜ë¡ ë†’ìŒ
        }
        
        results = {
            'score_statistics': score_stats,
            'correlations_with_features': correlations,
            'change_statistics': change_stats
        }
        
        return results
    
    def evaluate_threshold_sensitivity(self, 
                                     anomaly_scores: np.ndarray,
                                     thresholds: Optional[List[float]] = None) -> Dict:
        """
        ì„ê³„ê°’ ë³€í™”ì— ë”°ë¥¸ ë¯¼ê°ë„ ë¶„ì„
        
        Args:
            anomaly_scores: ì´ìƒ ì ìˆ˜
            thresholds: í…ŒìŠ¤íŠ¸í•  ì„ê³„ê°’ ë¦¬ìŠ¤íŠ¸
            
        Returns:
            Dict: ì„ê³„ê°’ ë¯¼ê°ë„ ë¶„ì„ ê²°ê³¼
        """
        if thresholds is None:
            # ê¸°ë³¸ ì„ê³„ê°’: 5%, 10%, 15%, 20%, 25%, 30%, 35%, 40%, 45%, 50%
            thresholds = [np.percentile(anomaly_scores, p) for p in [95, 90, 85, 80, 75, 70, 65, 60, 55, 50]]
        
        sensitivity_results = []
        
        for threshold in thresholds:
            # í•´ë‹¹ ì„ê³„ê°’ì—ì„œ ì´ìƒì¹˜ë¡œ ë¶„ë¥˜ëœ ë°ì´í„° ìˆ˜
            anomalies_detected = np.sum(anomaly_scores > threshold)
            anomaly_ratio = anomalies_detected / len(anomaly_scores)
            
            # ì„ê³„ê°’ ê·¼ì²˜ì˜ ë°ì´í„° ë¶„í¬
            near_threshold = np.sum(np.abs(anomaly_scores - threshold) < threshold * 0.1)
            near_threshold_ratio = near_threshold / len(anomaly_scores)
            
            sensitivity_results.append({
                'threshold': threshold,
                'anomalies_detected': anomalies_detected,
                'anomaly_ratio': anomaly_ratio,
                'near_threshold_count': near_threshold,
                'near_threshold_ratio': near_threshold_ratio
            })
        
        # ìµœì  ì„ê³„ê°’ ì¶”ì • (Elbow methodì™€ ìœ ì‚¬)
        # ì´ìƒì¹˜ ë¹„ìœ¨ì˜ ë³€í™”ìœ¨ì´ ê¸‰ê²©íˆ ë³€í•˜ëŠ” ì§€ì 
        ratios = [r['anomaly_ratio'] for r in sensitivity_results]
        ratio_changes = np.diff(ratios)
        optimal_idx = np.argmax(np.abs(ratio_changes))
        optimal_threshold = thresholds[optimal_idx]
        
        results = {
            'threshold_analysis': sensitivity_results,
            'optimal_threshold': optimal_threshold,
            'optimal_threshold_index': optimal_idx,
            'thresholds': thresholds
        }
        
        return results
    
    def evaluate_temporal_consistency(self, 
                                    anomaly_scores: np.ndarray,
                                    window_size: int = 10) -> Dict:
        """
        ì‹œê°„ì  ì¼ê´€ì„± í‰ê°€ (ì‹œê³„ì—´ ë°ì´í„°ìš©)
        
        Args:
            anomaly_scores: ì´ìƒ ì ìˆ˜
            window_size: ìœˆë„ìš° í¬ê¸°
            
        Returns:
            Dict: ì‹œê°„ì  ì¼ê´€ì„± í‰ê°€ ê²°ê³¼
        """
        # ì´ë™ í‰ê· ê³¼ í‘œì¤€í¸ì°¨
        moving_mean = pd.Series(anomaly_scores).rolling(window=window_size, center=True).mean().fillna(method='bfill').fillna(method='ffill')
        moving_std = pd.Series(anomaly_scores).rolling(window=window_size, center=True).std().fillna(method='bfill').fillna(method='ffill')
        
        # ì´ë™ í‰ê· ì—ì„œì˜ í¸ì°¨
        deviation_from_moving_mean = np.abs(anomaly_scores - moving_mean)
        
        # ì‹œê°„ì  ì•ˆì •ì„± ì§€ìˆ˜ (í¸ì°¨ê°€ ì‘ì„ìˆ˜ë¡ ë†’ìŒ)
        temporal_stability = 1.0 / (1.0 + np.mean(deviation_from_moving_mean))
        
        # ê¸‰ê²©í•œ ë³€í™” ì§€ì  íƒì§€
        score_changes = np.abs(np.diff(anomaly_scores))
        sudden_changes = score_changes > np.percentile(score_changes, 95)
        sudden_change_ratio = np.sum(sudden_changes) / len(sudden_changes)
        
        # ì—°ì†ëœ ì´ìƒì¹˜ íƒì§€
        high_scores = anomaly_scores > np.percentile(anomaly_scores, 90)
        consecutive_anomalies = self._find_consecutive_anomalies(high_scores)
        
        results = {
            'temporal_stability': temporal_stability,
            'moving_mean': moving_mean.values,
            'moving_std': moving_std.values,
            'deviation_from_moving_mean': deviation_from_moving_mean,
            'sudden_change_ratio': sudden_change_ratio,
            'sudden_changes': sudden_changes,
            'consecutive_anomalies': consecutive_anomalies,
            'max_consecutive_length': max(consecutive_anomalies) if consecutive_anomalies else 0
        }
        
        return results
    
    def evaluate_model_comparison(self, 
                                models_results: Dict[str, Dict],
                                data: pd.DataFrame) -> Dict:
        """
        ì—¬ëŸ¬ ëª¨ë¸ì˜ ê²°ê³¼ë¥¼ ë¹„êµ í‰ê°€
        
        Args:
            models_results: ëª¨ë¸ë³„ ê²°ê³¼ ë”•ì…”ë„ˆë¦¬
            data: ì›ë³¸ ë°ì´í„°
            
        Returns:
            Dict: ëª¨ë¸ ë¹„êµ í‰ê°€ ê²°ê³¼
        """
        comparison_results = {}
        
        for model_name, results in models_results.items():
            if 'anomaly_scores' not in results:
                continue
                
            anomaly_scores = results['anomaly_scores']
            
            # ê° ëª¨ë¸ì— ëŒ€í•œ ê°œë³„ í‰ê°€
            cluster_eval = self.evaluate_cluster_separation(data, anomaly_scores)
            stat_eval = self.evaluate_statistical_properties(anomaly_scores, data)
            threshold_eval = self.evaluate_threshold_sensitivity(anomaly_scores)
            temporal_eval = self.evaluate_temporal_consistency(anomaly_scores)
            
            comparison_results[model_name] = {
                'cluster_separation': cluster_eval,
                'statistical_properties': stat_eval,
                'threshold_sensitivity': threshold_eval,
                'temporal_consistency': temporal_eval
            }
        
        # ëª¨ë¸ ê°„ ë¹„êµ ì§€í‘œ
        if len(comparison_results) > 1:
            model_names = list(comparison_results.keys())
            
            # Silhouette Score ë¹„êµ
            silhouette_scores = [comparison_results[name]['cluster_separation']['silhouette_score'] 
                               for name in model_names]
            best_silhouette_model = model_names[np.argmax(silhouette_scores)]
            
            # ë¶„ë¦¬ ì§€ìˆ˜ ë¹„êµ
            separation_indices = [comparison_results[name]['cluster_separation']['separation_index'] 
                                for name in model_names]
            best_separation_model = model_names[np.argmax(separation_indices)]
            
            # ì‹œê°„ì  ì•ˆì •ì„± ë¹„êµ
            temporal_stabilities = [comparison_results[name]['temporal_consistency']['temporal_stability'] 
                                  for name in model_names]
            best_temporal_model = model_names[np.argmax(temporal_stabilities)]
            
            comparison_summary = {
                'best_silhouette_model': best_silhouette_model,
                'best_separation_model': best_separation_model,
                'best_temporal_model': best_temporal_model,
                'silhouette_scores': dict(zip(model_names, silhouette_scores)),
                'separation_indices': dict(zip(model_names, separation_indices)),
                'temporal_stabilities': dict(zip(model_names, temporal_stabilities))
            }
            
            comparison_results['comparison_summary'] = comparison_summary
        
        return comparison_results
    
    def generate_evaluation_report(self, 
                                 evaluation_results: Dict,
                                 save_path: Optional[str] = None) -> str:
        """
        í‰ê°€ ê²°ê³¼ë¥¼ ìš”ì•½í•œ ë¦¬í¬íŠ¸ ìƒì„±
        
        Args:
            evaluation_results: í‰ê°€ ê²°ê³¼
            save_path: ì €ì¥í•  íŒŒì¼ ê²½ë¡œ
            
        Returns:
            str: ìƒì„±ëœ ë¦¬í¬íŠ¸
        """
        report = []
        report.append("=" * 60)
        report.append("ë¹„ì§€ë„ ì´ìƒì¹˜ íƒì§€ ëª¨ë¸ í‰ê°€ ë¦¬í¬íŠ¸")
        report.append("=" * 60)
        report.append("")
        
        # ëª¨ë¸ë³„ ê²°ê³¼ ìš”ì•½
        for model_name, results in evaluation_results.items():
            if model_name == 'comparison_summary':
                continue
                
            report.append(f"ğŸ“Š {model_name} ëª¨ë¸ í‰ê°€ ê²°ê³¼")
            report.append("-" * 40)
            
            # êµ°ì§‘ ë¶„ë¦¬ ê²°ê³¼
            cluster = results['cluster_separation']
            report.append(f"êµ°ì§‘ ë¶„ë¦¬ ì„±ëŠ¥:")
            report.append(f"  - Silhouette Score: {cluster['silhouette_score']:.4f}")
            report.append(f"  - Davies-Bouldin Index: {cluster['davies_bouldin_index']:.4f}")
            report.append(f"  - ë¶„ë¦¬ ì§€ìˆ˜: {cluster['separation_index']:.4f}")
            report.append("")
            
            # í†µê³„ì  íŠ¹ì„±
            stats = results['statistical_properties']
            report.append(f"í†µê³„ì  íŠ¹ì„±:")
            report.append(f"  - ì´ìƒ ì ìˆ˜ í‰ê· : {stats['score_statistics']['mean']:.4f}")
            report.append(f"  - ì´ìƒ ì ìˆ˜ í‘œì¤€í¸ì°¨: {stats['score_statistics']['std']:.4f}")
            report.append(f"  - ì •ê·œë¶„í¬ ì—¬ë¶€: {'ì˜ˆ' if stats['score_statistics']['is_normal_distribution'] else 'ì•„ë‹ˆì˜¤'}")
            report.append("")
            
            # ì‹œê°„ì  ì¼ê´€ì„±
            temporal = results['temporal_consistency']
            report.append(f"ì‹œê°„ì  ì¼ê´€ì„±:")
            report.append(f"  - ì‹œê°„ì  ì•ˆì •ì„±: {temporal['temporal_stability']:.4f}")
            report.append(f"  - ê¸‰ê²©í•œ ë³€í™” ë¹„ìœ¨: {temporal['sudden_change_ratio']:.2%}")
            report.append(f"  - ìµœëŒ€ ì—°ì† ì´ìƒì¹˜ ê¸¸ì´: {temporal['max_consecutive_length']}")
            report.append("")
        
        # ëª¨ë¸ ë¹„êµ ê²°ê³¼
        if 'comparison_summary' in evaluation_results:
            summary = evaluation_results['comparison_summary']
            report.append("ğŸ† ëª¨ë¸ ë¹„êµ ê²°ê³¼")
            report.append("-" * 40)
            report.append(f"ìµœê³  Silhouette Score: {summary['best_silhouette_model']}")
            report.append(f"ìµœê³  ë¶„ë¦¬ ì§€ìˆ˜: {summary['best_separation_model']}")
            report.append(f"ìµœê³  ì‹œê°„ì  ì•ˆì •ì„±: {summary['best_temporal_model']}")
            report.append("")
            
            report.append("ğŸ“ˆ ìƒì„¸ ë¹„êµ ì§€í‘œ:")
            for metric_name, scores in [('Silhouette Score', summary['silhouette_scores']),
                                       ('ë¶„ë¦¬ ì§€ìˆ˜', summary['separation_indices']),
                                       ('ì‹œê°„ì  ì•ˆì •ì„±', summary['temporal_stabilities'])]:
                report.append(f"  {metric_name}:")
                for model, score in scores.items():
                    report.append(f"  - {model}: {score:.4f}")
                report.append("")
            
            # ì¢…í•© ì„±ëŠ¥ ì ìˆ˜ ì¶”ê°€ (ğŸ† ëª¨ë¸ ë¹„êµ ê²°ê³¼ ì„¹ì…˜ ì•„ë˜ì—)
            if 'combined_scores' in summary:
                report.append("ğŸ… ì¢…í•© ì„±ëŠ¥ ì ìˆ˜ (ì •ê·œí™”):")
                for model, score in summary['combined_scores'].items():
                    report.append(f"  - {model}: {score:.4f}")
                report.append("")
        
        report.append("ğŸ’¡ í‰ê°€ ì§€í‘œ í•´ì„ ê°€ì´ë“œ")
        report.append("-" * 40)
        report.append("â€¢ Silhouette Score: ë†’ì„ìˆ˜ë¡ ì¢‹ìŒ (ìµœëŒ€ 1.0)")
        report.append("â€¢ Davies-Bouldin Index: ë‚®ì„ìˆ˜ë¡ ì¢‹ìŒ")
        report.append("â€¢ ë¶„ë¦¬ ì§€ìˆ˜: ë†’ì„ìˆ˜ë¡ ì •ìƒ/ì´ìƒì¹˜ê°€ ì˜ ë¶„ë¦¬ë¨")
        report.append("â€¢ ì‹œê°„ì  ì•ˆì •ì„±: ë†’ì„ìˆ˜ë¡ ì•ˆì •ì ")
        report.append("â€¢ ê¸‰ê²©í•œ ë³€í™” ë¹„ìœ¨: ë‚®ì„ìˆ˜ë¡ ì•ˆì •ì ")
        report.append("")
        report.append("=" * 60)
        
        final_report = "\n".join(report)
        
        if save_path:
            with open(save_path, 'w', encoding='utf-8') as f:
                f.write(final_report)
        
        return final_report
    
    def _calculate_skewness(self, data: np.ndarray) -> float:
        """ì™œë„ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤."""
        if len(data) < 3:
            return 0.0
        mean = np.mean(data)
        std = np.std(data)
        if std == 0:
            return 0.0
        return np.mean(((data - mean) / std) ** 3)
    
    def _calculate_kurtosis(self, data: np.ndarray) -> float:
        """ì²¨ë„ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤."""
        if len(data) < 4:
            return 0.0
        mean = np.mean(data)
        std = np.std(data)
        if std == 0:
            return 0.0
        return np.mean(((data - mean) / std) ** 4) - 3
    
    def _find_consecutive_anomalies(self, anomaly_mask: np.ndarray) -> List[int]:
        """ì—°ì†ëœ ì´ìƒì¹˜ì˜ ê¸¸ì´ë¥¼ ì°¾ìŠµë‹ˆë‹¤."""
        consecutive_lengths = []
        current_length = 0
        
        for is_anomaly in anomaly_mask:
            if is_anomaly:
                current_length += 1
            else:
                if current_length > 0:
                    consecutive_lengths.append(current_length)
                    current_length = 0
        
        # ë§ˆì§€ë§‰ì— ì—°ì†ëœ ì´ìƒì¹˜ê°€ ìˆëŠ” ê²½ìš°
        if current_length > 0:
            consecutive_lengths.append(current_length)
        
        return consecutive_lengths if consecutive_lengths else [0]
